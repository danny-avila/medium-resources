{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0f52175-a7e8-45ab-a965-0d4a1e8e760e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers\n",
    "!pip install captum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90853bde-95df-4827-98af-70410794c502",
   "metadata": {},
   "source": [
    "# Tokenization Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d970c20-8f80-4421-bcc3-85a581cf9738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Instantiate tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "text = 'The movie is superb'\n",
    "\n",
    "# Tokenize input text\n",
    "text_ids = tokenizer.encode(text, add_special_tokens=True)\n",
    "\n",
    "# Print the tokens\n",
    "print(tokenizer.convert_ids_to_tokens(text_ids))\n",
    "# Output: ['[CLS]', 'The', 'movie', 'is', 'superb', '[SEP]']\n",
    "\n",
    "# Print the ids of the tokens\n",
    "print(text_ids)\n",
    "# Output: [101, 1109, 2523, 1110, 25876, 102]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e541e1-da3d-47dd-a278-7950b4fb0e54",
   "metadata": {},
   "source": [
    "# Minimal Example to Fetch the Embeddings of Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb12068-b429-4411-bda5-bedff656d387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "import torch\n",
    "# Instantiate BERT model\n",
    "model = BertModel.from_pretrained('bert-base-cased')\n",
    "\n",
    "embeddings = model.embeddings(torch.tensor([text_ids]))\n",
    "print(embeddings.size())\n",
    "# Output: torch.Size([1, 6, 768]), since there are 6 tokens in text_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1d6810-edf6-4b1d-a48e-44e034a32a90",
   "metadata": {},
   "source": [
    "# Specify Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea24f09-9fef-469c-8884-794fda046a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask = None):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6f1929-401c-40c2-a7a2-4a061380f633",
   "metadata": {},
   "source": [
    "# Load Model's Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da8d59e-4ed4-4ca2-bcdb-93857a9295e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertClassifier()\n",
    "model.load_state_dict(torch.load('path/to/bert_model.pt', map_location=torch.device('cpu')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d29dd60-b4cc-43d6-b5a7-44f56adca3be",
   "metadata": {},
   "source": [
    "# Define Model Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8bc95b-99f1-4087-a012-8306fe328daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model output\n",
    "def model_output(inputs):\n",
    "  return model(inputs)[0]\n",
    "\n",
    "# Define model input\n",
    "model_input = model.bert.embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04dae59-850a-4b11-9684-cdcba55c6e2c",
   "metadata": {},
   "source": [
    "# Instantiate Integrated Gradients Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e805ad-9c5d-40b6-bb9d-890eecde0945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import LayerIntegratedGradients\n",
    "lig = LayerIntegratedGradients(model_output, model_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86492c38-8201-4d54-aba0-de21e4966a42",
   "metadata": {},
   "source": [
    "# Construct Original and Baseline Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563b09b7-a6c2-4e67-bc11-2b25aa3a4a4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def construct_input_and_baseline(text):\n",
    "\n",
    "    max_length = 510\n",
    "    baseline_token_id = tokenizer.pad_token_id \n",
    "    sep_token_id = tokenizer.sep_token_id \n",
    "    cls_token_id = tokenizer.cls_token_id \n",
    "\n",
    "    text_ids = tokenizer.encode(text, max_length=max_length, truncation=True, add_special_tokens=False)\n",
    "   \n",
    "    input_ids = [cls_token_id] + text_ids + [sep_token_id]\n",
    "    token_list = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "  \n",
    "\n",
    "    baseline_input_ids = [cls_token_id] + [baseline_token_id] * len(text_ids) + [sep_token_id]\n",
    "    return torch.tensor([input_ids], device='cpu'), torch.tensor([baseline_input_ids], device='cpu'), token_list\n",
    "\n",
    "text = 'This movie is superb'\n",
    "input_ids, baseline_input_ids, all_tokens = construct_input_and_baseline(text)\n",
    "\n",
    "print(f'original text: {input_ids}')\n",
    "print(f'baseline text: {baseline_input_ids}')\n",
    "\n",
    "# Output: original text: tensor([[  101,  1109,  2523,  1110, 25876,   102]])\n",
    "# Output: baseline text: tensor([[101,   0,   0,   0,   0, 102]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa548b0-e738-45fe-bc0f-0d490427b79b",
   "metadata": {},
   "source": [
    "# Compute Attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db56682-41f3-46ec-b331-c81617391fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributions, delta = lig.attribute(inputs= input_ids,\n",
    "                                    baselines= baseline_input_ids,\n",
    "                                    return_convergence_delta=True\n",
    "                                    )\n",
    "print(attributions.size())\n",
    "# Output: torch.Size([1, 6, 768])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864769c7-2378-42a2-8f35-76bd44af63ac",
   "metadata": {},
   "source": [
    "# Compute Attribution for Each Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826a93e2-4b4b-430a-9c20-10cbb5ac08e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_attributions(attributions):\n",
    "\n",
    "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    \n",
    "    return attributions\n",
    "\n",
    "attributions_sum = summarize_attributions(attributions)\n",
    "print(attributions_sum.size())\n",
    "# Output: torch.Size([6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0123bbd3-536f-48cb-a0fa-c9a6fd9557df",
   "metadata": {},
   "source": [
    "# Visualize the Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2eaaa4-0fa4-4928-a7e2-a727f8e56fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import visualization as viz\n",
    "\n",
    "score_vis = viz.VisualizationDataRecord(\n",
    "                        word_attributions = attributions_sum,\n",
    "                        pred_prob = torch.max(model(input_ids)[0]),\n",
    "                        pred_class = torch.argmax(model(input_ids)[0]).numpy(),\n",
    "                        true_class = 1,\n",
    "                        attr_class = text,\n",
    "                        attr_score = attributions_sum.sum(),       \n",
    "                        raw_input_ids = all_tokens,\n",
    "                        convergence_score = delta)\n",
    "\n",
    "viz.visualize_text([score_vis])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c16834-2b58-4d96-b56b-f5908468f64a",
   "metadata": {},
   "source": [
    "# Encapsulate All the Steps Above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c9ec71-84ca-4734-afd0-b006c3a711df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_text(text, true_class):\n",
    "\n",
    "    input_ids, baseline_input_ids, all_tokens = construct_input_and_baseline(text)\n",
    "    attributions, delta = lig.attribute(inputs= input_ids,\n",
    "                                    baselines= baseline_input_ids,\n",
    "                                    return_convergence_delta=True\n",
    "                                    )\n",
    "    attributions_sum = summarize_attributions(attributions)\n",
    "\n",
    "    score_vis = viz.VisualizationDataRecord(\n",
    "                        word_attributions = attributions_sum,\n",
    "                        pred_prob = torch.max(model(input_ids)[0]),\n",
    "                        pred_class = torch.argmax(model(input_ids)[0]).numpy(),\n",
    "                        true_class = true_class,\n",
    "                        attr_class = text,\n",
    "                        attr_score = attributions_sum.sum(),       \n",
    "                        raw_input_ids = all_tokens,\n",
    "                        convergence_score = delta)\n",
    "\n",
    "    viz.visualize_text([score_vis])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57984aee-32e9-418a-a286-f35e0bc67b70",
   "metadata": {},
   "source": [
    "# Interpret Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d530db94-52fa-4c9a-a673-27247eac3b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"It's a heartfelt film about love, loss, and legacy\"\n",
    "true_class = 1\n",
    "interpret_text(text, true_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8544cb5c-3afd-45a7-ae82-7f9e692ff223",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"A noisy, hideous, and viciously cumbersome movie\"\n",
    "true_class = 0\n",
    "interpret_text(text, true_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
